{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZB16RvwSQYD"
   },
   "source": [
    "Copyright &copy; CAMMA, ICube, University of Strasbourg. All Rights Reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8OJJD-kSTcD"
   },
   "source": [
    "<div>\n",
    "<a href=\"https://cholectriplet2021.grand-challenge.org/\">\n",
    "<img src=\"https://raw.githubusercontent.com/DpkApt/evis_at/master/pictures/header.png\" align=\"left\"/>\n",
    "</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xu8aMfE5S74v"
   },
   "source": [
    "## <h1><center>Getting Started</center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceAz2udUTolO"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hLKusP2TpGJ"
   },
   "source": [
    "In this notebook, we provide sample code to help familiarize yourself with the challenge, the dataset and the metrics. These are minimal examples to help illustrate a simple deep learning pipeline applied on a small subset of the Action Triplet dataset, **CholecT50**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcQdB8OZWjcb"
   },
   "source": [
    "# Data Loading and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyjsFvOg3gso"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for this module\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "print(\"Libraries successfully imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1K8d3LssreJ"
   },
   "source": [
    "Here, we use a small subset of the CholecT50 dataset available at this link: https://seafile.unistra.fr/f/ba1427a82ecc4ce18566/?dl=1. If you are running this notebook on Colab, you can run the cell below to download and unzip the dataset to the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PSeXm7OSm_D3"
   },
   "outputs": [],
   "source": [
    "# Ignore this cell if you have already downloaded and extracted the dataset\n",
    "\n",
    "!wget -O CholecT50_sample.zip https://seafile.unistra.fr/f/ba1427a82ecc4ce18566/?dl=1\n",
    "!unzip CholecT50_sample.zip\n",
    "\n",
    "print(\"Dataset successfully extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kvzcRoaNYds7"
   },
   "outputs": [],
   "source": [
    "# Change the dataset_path mentioned below appropriately if you have exracted the data to a different directory \n",
    "\n",
    "dataset_path = './CholecT50_sample/'\n",
    "\n",
    "data_path = os.path.join(dataset_path, 'data')\n",
    "triplet_path = os.path.join(dataset_path, 'triplet')\n",
    "dict_path = os.path.join(dataset_path, 'dict')\n",
    "video_names = os.listdir(data_path)                                   \n",
    "\n",
    "print(\"Dataset paths successfully defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gk2y7u2s7i5J"
   },
   "outputs": [],
   "source": [
    "# Create dictionary mapping triplet ids to readable label\n",
    "\n",
    "with open(os.path.join(dict_path, 'triplet.txt'), 'r') as f:\n",
    "  triplet_info = f.readlines()\n",
    "  triplet_dict = {}\n",
    "  for l in triplet_info:\n",
    "    triplet_id, triplet_label = l.split(':')\n",
    "    triplet_dict[int(triplet_id)] = triplet_label.rstrip()\n",
    "\n",
    "print('Random triplet id and its human readable label\\n')\n",
    "random_triplet_id = np.random.choice(list(triplet_dict.keys()))\n",
    "print('Triplet id: ', random_triplet_id, '\\nReadable label: ', triplet_dict[random_triplet_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLDza6yst9-I"
   },
   "outputs": [],
   "source": [
    "def generator(data_path, triplet_path, video_names, batch_size, shuffle_videos=False):\n",
    "  \"\"\" Defines a simple generator that returns sequential batches of input images and  their \n",
    "      corresponding triplet labels, video names, and frame ids.\n",
    "        Args:\n",
    "            data_path:     Path to directory containing a folder for each video\n",
    "            triplet_path:  Path to folder containing a txt file for each video\n",
    "                           listing the frame id, and binary label for all of the 100 considered \n",
    "                           triplet classes\n",
    "            video_names:   Names of the videos that will be retruned by this generator. These names\n",
    "                           should correpond to a folder in data_path and a txt file in triplet path\n",
    "            batch_size:    Batch size of outputs yielded by the generator\n",
    "            shuffle_videos:To perform a shuffling of videos (Note: frames will be returned sequentially!)  \n",
    "        Returns:\n",
    "            image batch     : Batch of images\n",
    "            triplet batch   : Batch of triplet labels ([N] vectors)\n",
    "            video_name_batch: Batch of video name strings\n",
    "            frame_id_batch  : Batch of integer frame ids\n",
    "    \"\"\"\n",
    "\n",
    "  if shuffle_videos:\n",
    "    video_names = np.random.shuffle(video_names)\n",
    "\n",
    "  image_batch, triplet_batch, video_name_batch, frame_id_batch = [], [], [], []\n",
    "\n",
    "  for video_name in video_names:\n",
    "    with open(os.path.join(triplet_path, video_name + '.txt'), mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "\n",
    "        for line in reader:\n",
    "          line = np.array(line, np.int64)\n",
    "          frame_id, triplet_label = line[0], line[1:]\n",
    "          image_path = os.path.join(data_path, video_name, \"%06d.png\" %frame_id)\n",
    "          image = np.array(Image.open(image_path), np.float32) / 255.0\n",
    "\n",
    "          image_batch.append(image)\n",
    "          triplet_batch.append(triplet_label)\n",
    "          video_name_batch.append(video_name)\n",
    "          frame_id_batch.append(int(frame_id))\n",
    "\n",
    "          if len(frame_id_batch) == batch_size:\n",
    "            yield image_batch, triplet_batch, video_name_batch, frame_id_batch\n",
    "            image_batch, triplet_batch, video_name_batch, frame_id_batch = [], [], [], []\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0SZBNWSyf7g"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "gen = generator(data_path, triplet_path, video_names, batch_size)\n",
    "\n",
    "for images, triplet_labels, video_names, frame_ids in gen:\n",
    "  for batch in range(batch_size):\n",
    "    print('\\nVisualizing image...\\n')\n",
    "    print('Video name: ', video_names[batch], ' Frame_id', frame_ids[batch])\n",
    "    plt.imshow(images[batch])\n",
    "    plt.show()\n",
    "    print('\\nEncoding showing which of the 100 considered action triplets are represented in the image\\n')\n",
    "    print(triplet_labels[batch])\n",
    "    print('\\nReadable labels\\n')\n",
    "    for triplet in np.where(triplet_labels[batch])[0]:\n",
    "      print(triplet_dict[triplet])\n",
    "    \n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBl9-4gOWof0"
   },
   "source": [
    "#  Building and Running Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0rkzEkh4ysO"
   },
   "source": [
    "We build and perform a simple forward pass of an image through a few layer convolutional network to predict the probability of each of the considered triplets being represented in the input image.\n",
    "\n",
    "Note: Please run the cells in the previous module Data Loading and Visualization before running this module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxDnLbKQ35t7"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for this module. You can skip ahead if you prefer a PyTorch based example.\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"Libraries successfully imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JbM-RYZEJf4"
   },
   "source": [
    "Defining a simple neural network using tf.keras. You can skip ahead if you prefer to use torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vl65rM9IAmqi"
   },
   "outputs": [],
   "source": [
    "# Defining the neural network architecture\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    filters=16, kernel_size=3, strides=2, activation=\"relu\", input_shape=(480, 854, 3))\n",
    ")                 \n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides = 2, activation=\"relu\")) \n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides = 2, activation=\"relu\")) \n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides = 2, activation=\"relu\")) \n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides = 2, activation=\"relu\")) \n",
    "model.add(tf.keras.layers.Flatten())                                     \n",
    "model.add(tf.keras.layers.Dense(units=4096, activation=\"relu\"))                 \n",
    "model.add(tf.keras.layers.Dense(units=2048, activation=\"relu\"))            \n",
    "model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\"))    \n",
    "\n",
    "print(\"Neural network architecture successfully defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZ_Yp4e6A_Q-"
   },
   "outputs": [],
   "source": [
    "model.build([1, 480, 854, 3])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfaJhd471PZJ"
   },
   "source": [
    "Performing a simple forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aZ4baDLDAYS"
   },
   "outputs": [],
   "source": [
    "input_4d = np.expand_dims(images[0], axis=0)\n",
    "print('Performing a simple forward pass on our untrained network for a test image')\n",
    "plt.imshow(images[0])\n",
    "plt.show()\n",
    "print('\\nPrediction\\n')\n",
    "print(model.predict(input_4d)[0])\n",
    "print('\\nLabel\\n')\n",
    "print(triplet_labels[0])\n",
    "print('\\nReadable label\\n')\n",
    "for triplet_id in np.where(triplet_labels[0])[0]:\n",
    "  print(triplet_dict[triplet_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2M05KcCQ0eA"
   },
   "source": [
    "[**OPTIONAL**] Using PyTorch to make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvjIpgGkRKge"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for this module.\n",
    "\n",
    "import torch\n",
    "import numpy as np  \n",
    "from torch import nn\n",
    "from torch.nn import Module  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yj0iOFBzRnSp"
   },
   "outputs": [],
   "source": [
    "class MyModel(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, h, w):\n",
    "        super(MyModel, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.conv1 = nn.Conv2d(3, 32, (3,3))\n",
    "        self.conv2 = nn.Conv2d(32, 64, (3,3))\n",
    "        self.conv3 = nn.Conv2d(64, 128, (3,3))\n",
    "        self.conv4 = nn.Conv2d(128, 256, (3,3))\n",
    "        self.pool1 = nn.MaxPool2d((3,3), stride=(2,2))\n",
    "        self.pool2 = nn.MaxPool2d((2,2), stride=(2,2))\n",
    "        self.pool3 = nn.MaxPool2d((2,2), stride=(2,2))\n",
    "        self.h   = int(h/8 - 4)\n",
    "        self.w   = int(w/8 - 4)\n",
    "        self.mlp = nn.Linear(self.h*self.w*256, 100)        \n",
    "        self.act1 = nn.ReLU()\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.act3 = nn.ReLU()        \n",
    "        self.act4 = nn.Sigmoid()\n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.conv1(X)\n",
    "        X = self.act1(X)\n",
    "        X = self.pool1(X)\n",
    "        # second hidden layer\n",
    "        X = self.conv2(X)\n",
    "        X = self.act2(X)\n",
    "        X = self.pool2(X)\n",
    "        # second hidden layer\n",
    "        X = self.conv3(X)\n",
    "        X = self.act3(X)\n",
    "        X = self.pool3(X)\n",
    "        # second hidden layer\n",
    "        X = self.conv4(X)\n",
    "        # flatten\n",
    "        X = X.view(-1, self.h*self.w*256)\n",
    "        # output layer\n",
    "        X = self.mlp(X)\n",
    "        X = self.act4(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4z0Z9rcSMMd"
   },
   "outputs": [],
   "source": [
    "input_4d = np.expand_dims(images[0], axis=0)\n",
    "# Converting to Channel first. NHWC --> NCHW\n",
    "input_4d = np.transpose(input_4d, [0, 3, 1, 2])\n",
    "input_4d = torch.from_numpy(input_4d)\n",
    "print('Performing a simple forward pass on our untrained network for a test image')\n",
    "plt.imshow(images[0])\n",
    "plt.show()\n",
    "print('\\nPrediction\\n')\n",
    "model  = MyModel(480, 854)\n",
    "print(model(input_4d)[0])\n",
    "print('\\nLabel\\n')\n",
    "print(triplet_labels[0])\n",
    "print('\\nReadable label\\n')\n",
    "for triplet_id in np.where(triplet_labels[0])[0]:\n",
    "  print(triplet_dict[triplet_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_4F2W7uWs5V"
   },
   "source": [
    "#  Metrics and Evaluation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLK2JMF4ET2K"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for this module\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_s3vCa2_zwWd"
   },
   "outputs": [],
   "source": [
    "def _compute_AP(gt_labels, pd_probs, valid=None):\n",
    "    \"\"\" Compute the average precision (AP) of each of the 100 considered triplets.\n",
    "        Args:\n",
    "            gt_labels: 1D (batch of) vector[N] of integer values 0's or 1's for the groundtruth labels.\n",
    "            pd_probs:  1D (batch of) vector[N] of float values [0,1] for the predicted labels.\n",
    "        Returns:\n",
    "            results:   1D vector[N] of AP for each class \n",
    "    \"\"\"\n",
    "    gt_instances  = np.sum(gt_labels, axis=0)\n",
    "    pd_instances  = np.sum(pd_probs, axis=0)\n",
    "    computed_ap   = average_precision_score(gt_labels, pd_probs, average=None)\n",
    "    actual_ap     = []\n",
    "    num_classes   = np.shape(gt_labels)[-1]\n",
    "    for k in range(num_classes):\n",
    "        if ((gt_instances[k] != 0) or (pd_instances[k] != 0)) and not np.isnan(computed_ap[k]):\n",
    "            actual_ap.append(computed_ap[k])\n",
    "        else:\n",
    "            actual_ap.append(\"n/a\")\n",
    "    return actual_ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyNsVlS7zz_i"
   },
   "outputs": [],
   "source": [
    "def _average_by_videos(results):\n",
    "    \"\"\" Compute the average AP of each triplet class across all the videos\n",
    "        and mean AP of the model on the triplet predictions.\n",
    "        Args:\n",
    "            results:   1D (batch of) vector of AP for each class. One member of the batch corresponds\n",
    "                       to one video\n",
    "        Returns:\n",
    "            AP:   1D vector[N] of AP for each class averaged by videos\n",
    "    \"\"\"\n",
    "    n = results.shape[-1]\n",
    "    AP = []\n",
    "    for j in range(n):\n",
    "        x = results[:,j]\n",
    "        x = np.mean([float(a) for a in x if (str(a)!='n/a') ])\n",
    "        if np.isnan(x):\n",
    "            AP.append(\"n/a\")\n",
    "        else:          \n",
    "            AP.append(x)\n",
    "    mAP = np.mean( [i for i in AP if i !='n/a'])\n",
    "    return np.array(AP), mAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_RjhHJ6z1x6"
   },
   "outputs": [],
   "source": [
    "# example usage. Here we use randomly generated ground truth and predicted values\n",
    "\n",
    "half_0s = np.zeros(shape=[20,100], dtype=np.int64)\n",
    "half_1s = np.ones(shape=[20,100], dtype=np.int64)\n",
    "\n",
    "vid230_gt = np.concatenate((half_0s, half_1s), axis=0)\n",
    "vid231_gt = np.concatenate((half_1s, half_0s), axis=0)\n",
    "\n",
    "vid230_pd = np.random.random((40,100))\n",
    "vid231_pd = np.random.random((40,100))\n",
    "\n",
    "non_null  = list(range(0,93)) # for ignoring the null triplets\n",
    "ap_vid230 = _compute_AP(gt_labels=vid230_gt, pd_probs=vid230_pd, valid=non_null)\n",
    "ap_vid231 = _compute_AP(gt_labels=vid231_gt, pd_probs=vid231_pd, valid=non_null)\n",
    "\n",
    "ap_vid  = np.stack([ap_vid230, ap_vid231,], axis=0)\n",
    "AP,mAP  = _average_by_videos(results=ap_vid)\n",
    "\n",
    "print(AP, \"\\nmAP = \",mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3LZGSrs85K6"
   },
   "source": [
    "#  Saving Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_e5-i9jt88WW"
   },
   "source": [
    "A minimal working example to save your model results using a docker image is provided here: https://seafile.unistra.fr/f/a495966e56e84bf0a834/?dl=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYO7STWJMP99"
   },
   "source": [
    "# Supplementary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLULYdWEMahY"
   },
   "source": [
    "Optionally, if you want to incorporate labels for instruments, verbs and targets into your modelling. You can use the following code to decompose a triplet id into its corresponding instrument, verb and target ids, respectively, and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jed9QAAJMR9s"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for this module\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sl-bjvx6Nnkt"
   },
   "outputs": [],
   "source": [
    "# Ignore this cell if you have already downloaded and extracted the dataset\n",
    "\n",
    "!wget -O CholecT50_sample.zip https://seafile.unistra.fr/f/ba1427a82ecc4ce18566/?dl=1\n",
    "!unzip CholecT50_sample.zip\n",
    "\n",
    "print(\"Dataset successfully extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFgmFXInNSYJ"
   },
   "outputs": [],
   "source": [
    "num_instrument = 6\n",
    "num_verb     = 10\n",
    "num_target   = 15\n",
    "num_triplet  = 100\n",
    "map_dict_url = './CholecT50_sample/dict/maps.txt'\n",
    "maps_dict    = np.genfromtxt(map_dict_url, dtype=int, comments='#', delimiter=',', skip_header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FM2haCZvNahP"
   },
   "outputs": [],
   "source": [
    "def map_selector(component='iv'):\n",
    "    choices = {'ivt':0, 'i':1, 'v':2, 't':3, 'iv':4, 'it':5, 'vt':6, } \n",
    "    return  choices.get(component, 0) \n",
    "\n",
    "def decompose(inputs, component='i'):\n",
    "    \"\"\" Extract the component labels from the triplets. E.g.: from a triplet ID vector[100], get the vector [6] for the used instruments (i), or the vector [15] for the target acted upon. \n",
    "        Args:\n",
    "            inputs: a 1D vector of dimension (n), where n = number of triplet classes;\n",
    "                    with values int(0 or 1) for target labels and float[0, 1] for predicted labels.\n",
    "            component: a string for the component to extract; \n",
    "                    (e.g.: i for instrument, v for verb, t for target, iv for instrument-verb pair, it for instrument-target pair and vt (unused) for verb-target pair)\n",
    "        Returns:\n",
    "            output: int or float sparse encoding 1D vector of dimension (n), where n = number of component's classes.\n",
    "    \"\"\"\n",
    "    key    = map_selector(component)\n",
    "    index  = sorted(np.unique(maps_dict[:,key]))\n",
    "    output = []\n",
    "    for idx in index:\n",
    "        same_class = [i for i,x in enumerate(maps_dict[:,key]) if x==idx]\n",
    "        y = np.max(inputs[same_class])\n",
    "        output.append( y )        \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXUKqYRwNuEX"
   },
   "outputs": [],
   "source": [
    "# Create dictionary mapping triplet ids, instrument ids, verb ids and target ids to readable label\n",
    "\n",
    "dict_path = './CholecT50_sample/dict/'\n",
    "\n",
    "with open(os.path.join(dict_path, 'triplet.txt'), 'r') as f:\n",
    "  triplet_info = f.readlines()\n",
    "  triplet_dict = {}\n",
    "  for l in triplet_info:\n",
    "    triplet_id, triplet_label = l.split(':')\n",
    "    triplet_dict[int(triplet_id)] = triplet_label.rstrip()\n",
    "\n",
    "with open(os.path.join(dict_path, 'instrument.txt'), 'r') as f:\n",
    "  instrument_info = f.readlines()\n",
    "  instrument_dict = {}\n",
    "  for l in instrument_info:\n",
    "    instrument_id, instrument_label = l.split(':')\n",
    "    instrument_dict[int(instrument_id)] = instrument_label.rstrip()\n",
    "\n",
    "with open(os.path.join(dict_path, 'verb.txt'), 'r') as f:\n",
    "  verb_info = f.readlines()\n",
    "  verb_dict = {}\n",
    "  for l in verb_info:\n",
    "    verb_id, verb_label = l.split(':')\n",
    "    verb_dict[int(verb_id)] = verb_label.rstrip()\n",
    "\n",
    "with open(os.path.join(dict_path, 'target.txt'), 'r') as f:\n",
    "  target_info = f.readlines()\n",
    "  target_dict = {}\n",
    "  for l in target_info:\n",
    "    target_id, target_label = l.split(':')\n",
    "    target_dict[int(target_id)] = target_label.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8gu9R4qPcoS"
   },
   "outputs": [],
   "source": [
    "print('Random triplet id and its human readable label\\n')\n",
    "random_triplet_id = np.random.choice(list(triplet_dict.keys()))\n",
    "print('Triplet id: ', random_triplet_id, '\\nReadable label: ', triplet_dict[random_triplet_id])\n",
    "\n",
    "one_hot_triplet = np.zeros(100)\n",
    "one_hot_triplet[random_triplet_id] = 1\n",
    "\n",
    "instrument_id = np.where(decompose(one_hot_triplet, 'i'))[0][0]\n",
    "verb_id = np.where(decompose(one_hot_triplet, 'v'))[0][0]\n",
    "target_id = np.where(decompose(one_hot_triplet, 't'))[0][0]\n",
    "\n",
    "print('Instrument id: ', instrument_id, '\\nReadable label: ', instrument_dict[instrument_id])\n",
    "print('Verb id: ', verb_id, '\\nReadable label: ', verb_dict[verb_id])\n",
    "print('Target id: ', target_id, '\\nReadable label: ', target_dict[target_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNlvHE48SpaI"
   },
   "source": [
    "Additionally, if you want to learn the triplet as a 3d matrix of interaction as done in [Nwoye C.I. et.al, Recognition of Instrument-Tissue Interactions in Endoscopic Videos via Action Triplets, MICCAI 2020](https://arxiv.org/abs/2007.05405), we provide code below to map the a vector of triplet ids to its corresponding 3D matrix and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvaXJujCQIlb"
   },
   "outputs": [],
   "source": [
    "\n",
    "def project_1d_to_3d(inputs):\n",
    "    \"\"\" Convert triplets labels from 1D vector to 3D matrix of interaction.\n",
    "        Args:\n",
    "            inputs: a 1D vector of dimension (n), where n = number of triplet classes;\n",
    "            with values int(0 or 1) for target labels and float[0, 1] for predicted labels.\n",
    "        Returns:\n",
    "            output: int or float sparse encoding 3D matrix of dimension (nI, nV, nT);\n",
    "            where nI = number of instrument classes,  nV = number of verb classes,  nT = number of target classes\n",
    "    \"\"\"\n",
    "    d3    = np.zeros([num_instrument, num_verb, num_target], dtype=np.float32)      \n",
    "    for idx, val in enumerate(inputs):\n",
    "        d3[maps_dict[idx,1], maps_dict[idx,2], maps_dict[idx,3]] = val\n",
    "    return d3\n",
    "    \n",
    "def project_3d_to_1d(self, inputs):\n",
    "    \"\"\" Convert triplets labels from 3D vector to 1D matrix of interaction.\n",
    "        Args:\n",
    "            inputs: a 3D matrix of dimension (nI, nV, nT);\n",
    "            where nI = number of instrument classes,  nV = number of verb classes,  nT = number of target classes\n",
    "        Returns:\n",
    "            output: int or float sparse encoding 1D vector of dimension (n), where n = number of triplet classes;\n",
    "            with values int(0 or 1) for target labels and float[0, 1] for predicted labels.\n",
    "    \"\"\"\n",
    "    d1   = np.zeros([num_triplet], dtype=np.float32)      \n",
    "    for idx in range(num_triplet):\n",
    "        d1[idx] = inputs[maps_dict[idx,1], maps_dict[idx,2], maps_dict[idx,3]]\n",
    "    return d1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Getting Started.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
